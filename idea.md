
对于我们的微应用所设计的这个调音AI，之前其所有的能力是：
1. 能看到当前的滤波器设置。
2. 能通过输出的特定格式内容，编辑对应的滤波器。

现在我们有一个新的后端服务：
其作用是：
用户输入类似：“我想要A耳机的高频，B耳机的低频。”
LLM将对应需求转换为符合：`coverSegementFromLLM`的传入。
datagroup不用管。
我们微前端解析之后，带着LLM整理好的参数，请求对应的父应用方法。

这还需要前置的其他修改：
1. LLM不知道我们产品的准确名字&LLMID，这需要用户在query LLM的时候就给到，因此：
   这需要，用户能够通过 `evaluation`接口，去拿到这个内容，具体来说：
   用户需要一个类似模糊搜索的工具在前端
   ，一旦检测到用户输入 @ 或者其他字符
   触发这个功能。
   要求： ![1761959347799](image/update_plan/1761959347799.png)
   类似这个图的效果。（被选的项目是 产品的名字）
   用户输@之后，会有一个高亮在这里。
   用户一旦选定，则：![1761959700399](image/update_plan/1761959700399.png)类似这里，选定之后，用户的搜索框里面会呈现出这样一个被高亮过的产品名字（ie800，榭兰图）。
   与此同时，这个高亮过的文本需要对应的是一个被特定符号包裹的元信息（我们可以定义<user_selected_item>{"name":"耳机名","uuid":"耳机uuid"}</user_selected_item>）这个内容对用户是不可见的，但是是最后发给LLM的内容。
   只有有符合这个条件的内容，LLM才会使用对应的能力。
2. 需要考虑对应的渲染逻辑，信息展示逻辑。
3. 要考虑用户有没有可能会出现什么错误的修改，导致破坏了那部分的元数据，一定要避免的情况是，LLM输出了一个调用父方法的请求，但是请求里面的uuid是错误的/数据库没有的。